{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LewisHamilton', 'SebastianVettel', 'MaxVerstappen', 'KarlLauterbach', 'CristianoRonaldo', 'LionelMessi', 'EdSheeran', 'TomCruise', 'HeleneFischer', 'Rihanna', 'GÃ¼ntherJauch', 'StefanRaab', 'HeidiKlum', 'Nena', 'ManuelNeuer', \"ElyasM'barek\", 'JudithRakers', 'AngelaMerkel', 'WladimirPutin', 'OlafScholz', 'JoeBiden', 'DonaldTrump', 'ChristianLindner', 'AnnalenaBaerbock', 'ElonMusk', 'JeffBezos', 'BarackObama', 'ChrisPratt', 'XiJinping', 'DwayneJohnson', 'MacKenzieScott', 'AnthonyFauci']\n"
     ]
    }
   ],
   "source": [
    "text_file = open(\"./assets/list_promis.txt\", \"r\")\n",
    "query_array = text_file.read().split(',\\n')\n",
    "print(query_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/src/images\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "datapath = os.getcwd() + \"/dataset/\"\n",
    "outpath = os.getcwd() + \"/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_val_test(dataset_dir, label_map):\n",
    "    return tuple(map(lambda set_: object_detector.DataLoader.from_pascal_voc(images_dir=os.path.join(dataset_dir, set_), annotations_dir=os.path.join(dataset_dir, set_), label_map=label_map), (\"train\", \"val\", \"test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Cache will be stored in /tmp/tmp5oeqtwfp with prefix filename 7bee435cfee6949ada7cad38d32e815e. Cache_prefix is /tmp/tmp5oeqtwfp/7bee435cfee6949ada7cad38d32e815e\n",
      "INFO:tensorflow:On image 0\n",
      "INFO:tensorflow:On image 100\n",
      "INFO:tensorflow:On image 200\n",
      "INFO:tensorflow:On image 300\n",
      "INFO:tensorflow:On image 400\n",
      "INFO:tensorflow:On image 500\n",
      "INFO:tensorflow:On image 600\n",
      "INFO:tensorflow:On image 700\n",
      "INFO:tensorflow:On image 800\n",
      "INFO:tensorflow:On image 900\n",
      "INFO:tensorflow:On image 1000\n",
      "INFO:tensorflow:On image 1100\n",
      "INFO:tensorflow:On image 1200\n",
      "INFO:tensorflow:On image 1300\n",
      "INFO:tensorflow:On image 1400\n",
      "INFO:tensorflow:On image 1500\n",
      "INFO:tensorflow:On image 1600\n",
      "INFO:tensorflow:On image 1700\n",
      "INFO:tensorflow:On image 1800\n",
      "INFO:tensorflow:On image 1900\n",
      "INFO:tensorflow:On image 2000\n",
      "INFO:tensorflow:On image 2100\n",
      "INFO:tensorflow:On image 2200\n",
      "INFO:tensorflow:On image 2300\n",
      "INFO:tensorflow:On image 2400\n",
      "INFO:tensorflow:On image 2500\n",
      "INFO:tensorflow:On image 2600\n",
      "INFO:tensorflow:On image 2700\n",
      "INFO:tensorflow:On image 2800\n",
      "INFO:tensorflow:On image 2900\n",
      "INFO:tensorflow:On image 3000\n",
      "INFO:tensorflow:On image 3100\n",
      "INFO:tensorflow:On image 3200\n",
      "INFO:tensorflow:On image 3300\n",
      "INFO:tensorflow:On image 3400\n",
      "INFO:tensorflow:On image 3500\n",
      "INFO:tensorflow:On image 3600\n",
      "INFO:tensorflow:On image 3700\n",
      "INFO:tensorflow:On image 3800\n",
      "INFO:tensorflow:On image 3900\n",
      "INFO:tensorflow:On image 4000\n",
      "INFO:tensorflow:On image 4100\n",
      "INFO:tensorflow:On image 4200\n",
      "INFO:tensorflow:On image 4300\n",
      "INFO:tensorflow:On image 4400\n",
      "INFO:tensorflow:Cache will be stored in /tmp/tmpsc6oef29 with prefix filename 5eea5b9312bd58fd9725d2a3a736893c. Cache_prefix is /tmp/tmpsc6oef29/5eea5b9312bd58fd9725d2a3a736893c\n",
      "INFO:tensorflow:On image 0\n",
      "INFO:tensorflow:On image 100\n",
      "INFO:tensorflow:On image 200\n",
      "INFO:tensorflow:On image 300\n",
      "INFO:tensorflow:On image 400\n",
      "INFO:tensorflow:On image 500\n",
      "INFO:tensorflow:On image 600\n",
      "INFO:tensorflow:On image 700\n",
      "INFO:tensorflow:On image 800\n",
      "INFO:tensorflow:On image 900\n",
      "INFO:tensorflow:Cache will be stored in /tmp/tmpe_blkbew with prefix filename fd42585a6188df7d3abc4e516ad0ebb5. Cache_prefix is /tmp/tmpe_blkbew/fd42585a6188df7d3abc4e516ad0ebb5\n",
      "INFO:tensorflow:On image 0\n",
      "INFO:tensorflow:On image 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6803a6876940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabelmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_train_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f0eea7cb3578>\u001b[0m in \u001b[0;36mread_train_val_test\u001b[0;34m(dataset_dir, label_map)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_train_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pascal_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f0eea7cb3578>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(set_)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_train_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pascal_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/data_util/object_detector_dataloader.py\u001b[0m in \u001b[0;36mfrom_pascal_voc\u001b[0;34m(cls, images_dir, annotations_dir, label_map, annotation_filenames, ignore_difficult_instances, num_shards, max_num_images, cache_dir, cache_prefix_filename)\u001b[0m\n\u001b[1;32m    215\u001b[0m           \u001b[0mmax_num_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_num_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m           ignore_difficult_instances=ignore_difficult_instances)\n\u001b[0;32m--> 217\u001b[0;31m       cache_writer.write_files(\n\u001b[0m\u001b[1;32m    218\u001b[0m           \u001b[0mcache_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m           \u001b[0mannotations_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/data_util/object_detector_dataloader_util.py\u001b[0m in \u001b[0;36mwrite_files\u001b[0;34m(self, cache_files, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'On image %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m       tf_example = create_pascal_tfrecord.dict_to_tf_example(\n\u001b[0m\u001b[1;32m    253\u001b[0m           \u001b[0mxml_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/third_party/efficientdet/dataset/create_pascal_tfrecord.py\u001b[0m in \u001b[0;36mdict_to_tf_example\u001b[0;34m(data, images_dir, label_map_dict, unique_id, ignore_difficult_instances, ann_json_dict)\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0mfull_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mencoded_jpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0mencoded_jpg_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_jpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_jpg_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;34m\"\"\"Make usable with \"with\" statement.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mwrite\u001b[0m \u001b[0mmight\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mreplicated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \"\"\"\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labelmap = query_array\n",
    "train_data, validation_data, test_data = read_train_val_test(datapath, labelmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"x\": self.x,\n",
    "            \"y\": self.y,\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.to_json())\n",
    "\n",
    "class BoundingBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.center = Point((xmin + xmax) // 2, (ymin + ymax) // 2)\n",
    "        self.width = xmax - xmin\n",
    "        self.height = ymax - ymin\n",
    "        self.area = self.width * self.height\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"xmin\": self.xmin,\n",
    "            \"ymin\": self.ymin,\n",
    "            \"xmax\": self.xmax,\n",
    "            \"ymax\": self.ymax,\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.to_json())\n",
    "\n",
    "class Detection:\n",
    "    def __init__(self, class_, confidence, xmin, ymin, xmax, ymax):\n",
    "        self.class_ = class_\n",
    "        self.confidence = confidence\n",
    "        self.bounding_box = BoundingBox(xmin=xmin, ymin=ymin, xmax=xmax, ymax=ymax)\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"class\": self.class_,\n",
    "            \"confidence\": self.confidence,\n",
    "            \"box\": self.bounding_box.to_json(),\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.to_json())\n",
    "\n",
    "\n",
    "class EfficientDetLite:\n",
    "    def __init__(self, model_path, labelmap):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "\n",
    "        # iti = input tensor index\n",
    "        input_details = self.interpreter.get_input_details()\n",
    "        self.iti_image = input_details[0][\"index\"]\n",
    "        self.it_image_dtype = input_details[0][\"dtype\"]\n",
    "        self.it_image_width = input_details[0][\"shape\"][2]\n",
    "        self.it_image_height = input_details[0][\"shape\"][1]\n",
    "\n",
    "        # oti = output tensor index\n",
    "        output_details = self.interpreter.get_output_details()\n",
    "        self.oti_bounding_boxes = output_details[1][\"index\"]\n",
    "        self.oti_classes = output_details[3][\"index\"]\n",
    "        self.oti_confidences = output_details[0][\"index\"]\n",
    "\n",
    "        self.labelmap = labelmap\n",
    "\n",
    "    def detect(self, image, threshold=0):\n",
    "        input_tensor = self.prepare_image(image)\n",
    "        self.interpreter.set_tensor(self.iti_image, input_tensor)\n",
    "        self.interpreter.invoke()\n",
    "\n",
    "        bounding_boxes = self.interpreter.get_tensor(self.oti_bounding_boxes)[0]\n",
    "        classes = self.interpreter.get_tensor(self.oti_classes)[0]\n",
    "        confidences = self.interpreter.get_tensor(self.oti_confidences)[0]\n",
    "        detections = zip(classes, bounding_boxes, confidences)\n",
    "        detections = filter(lambda x: x[2] >= threshold, detections)\n",
    "\n",
    "        def tensors2detection(x):\n",
    "            def clamp(n, min_, max_):\n",
    "                return max(min(max_, n), min_)\n",
    "\n",
    "            xmin = clamp(int(round(x[1][1] * image.shape[1])), 0, image.shape[1])\n",
    "            ymin = clamp(int(round(x[1][0] * image.shape[0])), 0, image.shape[0])\n",
    "            xmax = clamp(int(round(x[1][3] * image.shape[1])), 0, image.shape[1])\n",
    "            ymax = clamp(int(round(x[1][2] * image.shape[0])), 0, image.shape[0])\n",
    "            name = str(self.labelmap[int(x[0])])\n",
    "            confidence = float(x[2])\n",
    "\n",
    "            detection = Detection(name, confidence, xmin, ymin, xmax, ymax)\n",
    "            return detection\n",
    "\n",
    "        detections = map(lambda x: tensors2detection(x), detections)\n",
    "        detections = list(detections)\n",
    "        return detections\n",
    "\n",
    "    def prepare_image(self, image):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (self.it_image_width, self.it_image_height), interpolation=cv2.INTER_NEAREST)\n",
    "        tensor = np.reshape(image, (1, self.it_image_height, self.it_image_width, 3))\n",
    "        tensor = tensor.astype(self.it_image_dtype)\n",
    "        return tensor\n",
    "\n",
    "def show_image(image, label=None, scale=1):\n",
    "    show_images([image], labels=[label] if label is not None else None, scale=scale)\n",
    "\n",
    "\n",
    "def show_images(images, labels=None, scale=1):\n",
    "    figsize = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.figure(figsize=(figsize[0] * scale, figsize[1] * scale))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        image = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "        if labels is not None:\n",
    "            plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_detection(image, detection, scale=1, thickness=1, colors=None, confidence=True):\n",
    "    show_image(draw_detections(image,\n",
    "                               [detection],\n",
    "                               scale=scale,\n",
    "                               thickness=thickness,\n",
    "                               colors=colors,\n",
    "                               confidence=confidence))\n",
    "\n",
    "\n",
    "def show_detections(image, detections, scale=1, thickness=1, colors=None, confidence=True):\n",
    "    show_image(draw_detections(image,\n",
    "                               detections,\n",
    "                               scale=scale,\n",
    "                               thickness=thickness,\n",
    "                               colors=colors,\n",
    "                               confidence=confidence))\n",
    "\n",
    "\n",
    "def draw_detection(image, detection, scale=1, thickness=1, colors=None, confidence=True):\n",
    "    return draw_detections(image, [detection], scale, thickness, colors, confidence)\n",
    "\n",
    "\n",
    "def draw_detections(image, detections, scale=1, thickness=1, colors=None, confidence=True):\n",
    "    colors = {} if colors is None else {k: tuple(reversed(v)) for k, v in colors.items()}\n",
    "    result = image.copy()\n",
    "    for detection in detections:\n",
    "        xmin = int(detection.bounding_box.xmin)\n",
    "        ymin = int(detection.bounding_box.ymin)\n",
    "        xmax = int(detection.bounding_box.xmax)\n",
    "        ymax = int(detection.bounding_box.ymax)\n",
    "        color = colors.get(detection.class_)\n",
    "        if color is None:\n",
    "            color = (0, 0, 0)\n",
    "        result = cv2.rectangle(result, (xmin, ymin), (xmax, ymax), color, thickness)\n",
    "        if confidence:\n",
    "            text = \"{:.2f}\".format(float(detection.confidence))\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            textsize = cv2.getTextSize(text, font, scale, thickness)[0]\n",
    "            result = cv2.putText(result,\n",
    "                                 text,\n",
    "                                 (\n",
    "                                     ((xmin + xmax) - textsize[0]) // 2,\n",
    "                                     ((ymin + ymax) + textsize[1]) // 2\n",
    "                                 ),\n",
    "                                 font,\n",
    "                                 scale,\n",
    "                                 color,\n",
    "                                 thickness,\n",
    "                                 cv2.LINE_AA)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientDetLite(outpath + 'model.tflite', labelmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(datapath + 'test/087_b403b801.jpg') # change to exisiting image\n",
    "\n",
    "print(image)\n",
    "\n",
    "detections = model.detect(image, threshold=0.6)\n",
    "\n",
    "for detection in detections:\n",
    "  print(detection)\n",
    "\n",
    "show_detections(image, detections, thickness=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
