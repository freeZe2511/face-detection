{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs.full.helper as h\n",
    "\n",
    "from imp import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = h.directory\n",
    "OC_Net = h.OC_Net\n",
    "df = h.df\n",
    "image_directory = h.image_directory\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "img_size = 224\n",
    "mask_describe = ['face_with_mask',\"face_no_mask\"]\n",
    "labels={'mask':0,'without mask':1}\n",
    "type_mask = []\n",
    "fileste= \".json\"\n",
    "\n",
    "def get_bounding(j,i,data,labels_item):\n",
    "    x,y,w,h = j[\"BoundingBox\"]\n",
    "    img = cv2.imread(os.path.join(image_directory,i),1)\n",
    "    img = img[y:h,x:w]\n",
    "    img = cv2.resize(img,(img_size,img_size))\n",
    "    data.append([img,labels_item])\n",
    "    \n",
    "def get_json_file(PathName):\n",
    "    with open(PathName,'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "for i in df[\"name\"].unique():\n",
    "    f = i+fileste\n",
    "    for j in get_json_file(os.path.join(directory,f)).get(\"Annotations\"):\n",
    "        if j[\"classname\"] in mask_describe[0]:\n",
    "            get_bounding(j,i,data,labels['mask'])\n",
    "            type_mask.append(labels['mask'])\n",
    "            \n",
    "        if j[\"classname\"] in mask_describe[1]:\n",
    "            get_bounding(j,i,data,labels['without mask'])\n",
    "            type_mask.append(labels['without mask'])\n",
    "\n",
    "random.shuffle(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(type_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "for f,l in data:\n",
    "    features.append(f)\n",
    "    labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)/255.0\n",
    "features = features.reshape(-1,img_size,img_size,3)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(np.unique(labels))\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "base_model_mobile = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "\n",
    "for layer in base_model_mobile.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_mobile = Sequential()\n",
    "model_mobile.add(base_model_mobile)\n",
    "model_mobile.add(Flatten())\n",
    "model_mobile.add(Dense(1,activation='sigmoid'))\n",
    "model_mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f,val_f,train_l,val_l=train_test_split(features, labels,train_size=0.8,random_state=0)\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range= 17,    \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,  \n",
    "        zca_epsilon = 1e-05, \n",
    "        horizontal_flip=True, \n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range = [0.1, 10], \n",
    ")\n",
    "datagen.fit(train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_mobile.compile(loss='binary_crossentropy', optimizer='adam' ,metrics=['accuracy'])\n",
    "\n",
    "history_mobile = model_mobile.fit(datagen.flow(train_f, train_l, batch_size=32),\n",
    "                   steps_per_epoch=train_f.shape[0]//32,\n",
    "                   epochs=15,\n",
    "                   verbose=1,\n",
    "                   validation_data=(val_f, val_l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_list = []\n",
    "history_list.append(history_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobile.evaluate(val_f, val_l)\n",
    "prediction_mobile = model_mobile.predict(val_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobile.save(h.modelsVMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#1 \n",
    "fig,ax = plt.subplots(figsize=(22,20))\n",
    "\n",
    "print(ax)\n",
    "ax7 = fig.add_subplot(1,2,1)\n",
    "ax8 = fig.add_subplot(1,2,2)\n",
    "\n",
    "#3\n",
    "ax7.plot(history_mobile.history['accuracy'])\n",
    "ax7.plot(history_mobile.history['val_accuracy'])\n",
    "ax7.set_title('mobileNet Training accuracy vs Validation accuracy')\n",
    "ax7.set_ylabel('accuracy')\n",
    "ax7.set_xlabel('Epoch')\n",
    "ax7.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "ax8.plot(history_mobile.history['loss'])\n",
    "ax8.plot(history_mobile.history['val_loss'])\n",
    "ax8.set_title('mobileNet Training Loss vs Validation Loss')\n",
    "ax8.set_ylabel('Loss')\n",
    "ax8.set_xlabel('Epoch')\n",
    "ax8.legend(['Train', 'Validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(face):\n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = np.asarray(image)\n",
    "    return face_array\n",
    "\n",
    "def get_label(frame,img_size):\n",
    "    im = cv2.resize(frame,(img_size,img_size))\n",
    "    im = np.array(im)/255.0\n",
    "    im = im.reshape(1,img_size,img_size,3)\n",
    "    result = model.predict(im)\n",
    "    label_Y=1 if result>0.3 else 0\n",
    "    return label_Y,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 images to test and display\n",
    "test_img = [\"0015.jpg\",\"0834.jpg\",\"0675.jpg\",\"1035.jpeg\"]\n",
    "image_test_directory = h.image_test_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_mobile\n",
    "\n",
    "# adjust image darker and light \n",
    "adjust_light,rows,cols = 2.2,3,2\n",
    "figure= plt.figure(figsize = (14,14))\n",
    "axes = []\n",
    "assign = {'0':'Mask','1':\"No Mask\"}\n",
    "face_list = [] # save no mask\n",
    "\n",
    "for j,im in enumerate(test_img):\n",
    "    image =  cv2.imread(os.path.join(image_test_directory,im),1)\n",
    "    back_image = image\n",
    "    image = cv2.LUT(image.astype(np.uint8), np.array([((i / 255.0) ** (1.0 / adjust_light)) * 255 for i in np.arange(0, 256)]).astype(np.uint8))\n",
    "    blob = cv2.dnn.blobFromImage(image=cv2.resize(image, (300,300)), scalefactor=1.0, size=(300, 300), mean=(104.0, 177.0, 123.0))\n",
    "    \n",
    "    OC_Net.setInput(blob)\n",
    "    detections = OC_Net.forward()\n",
    "    length = detections.shape[2]\n",
    "    (hight, width) = image.shape[:2]\n",
    "    for i in range(0, length):\n",
    "        # get the face box\n",
    "        boxs = detections[0, 0, i, 3:7] * np.array([width, hight, width, hight])\n",
    "        (startX, startY, endX, endY) = boxs.astype(\"int\")\n",
    "        frame = image[startY:endY, startX:endX]\n",
    "        \n",
    "        # according to the confidence_threshold, to get the label\n",
    "        confidence_threshold = detections[0, 0, i, 2]\n",
    "        if confidence_threshold > 0.4:\n",
    "            label_Y,result = get_label(frame,img_size)\n",
    "            print(label_Y,result)\n",
    "           \n",
    "            # add the Text\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "            cv2.putText(image,assign[str(label_Y)] + \"{: .2f}\".format(float(result)) , (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (36,255,12), 2)\n",
    "            \n",
    "            ## save nomask people mesage\n",
    "            if(label_Y==1):\n",
    "                print(\"1\")\n",
    "#                     plt.imshow(back_image)\n",
    "                face_list.append(im)\n",
    "                print(im)\n",
    "\n",
    "    axes.append(figure.add_subplot(rows, cols, j+1))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
