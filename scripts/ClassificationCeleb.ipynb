{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ipynb.fs.full.helper' (/tf/src/scripts/helper.ipynb)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipynb.fs.full.helper as h\n",
    "\n",
    "from imp import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, shutil, random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "from retinaface import RetinaFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unknown pictures e.g. from one of those datasets\n",
    "# https://analyticsindiamag.com/10-face-datasets-to-start-facial-recognition-projects/\n",
    "# and unpack them in the /images/unknown/original folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = h.unknownOriginal\n",
    "cropped = h.unknownCropped\n",
    "\n",
    "myFiles = [f for f in os.listdir(original) if f.endswith('.jpg')]\n",
    "    \n",
    "for file in range(len(myFiles)):\n",
    "    \n",
    "    file_name = myFiles[file]\n",
    "    try:         \n",
    "        img = cv2.imread(original + \"/\" + file_name)\n",
    "        faces = RetinaFace.detect_faces(img)\n",
    "            \n",
    "        for i in range(len(faces)):\n",
    "            face = faces[f'face_{i+1}']['facial_area']\n",
    "            (xmin,ymin,xmax,ymax) = face\n",
    "            crop = img[ymin:ymax,xmin:xmax]\n",
    "            crop = cv2.resize(crop,(224,224))\n",
    "                \n",
    "        plt.imsave(cropped + \"/\" + file_name, cv2.cvtColor(crop, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "    except ValueError:\n",
    "        print(ValueError)\n",
    "        print(file_name)\n",
    "            \n",
    "    except TypeError:\n",
    "        print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    imageFolder = h.unknownCropped\n",
    "    folder = 'Unknown'\n",
    "\n",
    "    myFiles = [f for f in os.listdir(imageFolder) if f.endswith('.jpg')]\n",
    "    random.shuffle(myFiles)\n",
    "    \n",
    "    for i, file in enumerate(myFiles):\n",
    "        if(i <= int(len(myFiles) * 0.8)):\n",
    "            if not os.path.exists(f'{h.celebTrain}/{folder}'):\n",
    "                os.mkdir(f'{h.celebTrain}/{folder}')\n",
    "            shutil.copy(f'{imageFolder}/{file}', f'{h.celebTrain}/{folder}/{file}')\n",
    "        else:\n",
    "            if not os.path.exists(f'{h.celebTest}/{folder}'):\n",
    "                os.mkdir(f'{h.celebTest}/{folder}')\n",
    "            shutil.copy(f'{imageFolder}/{file}', f'{h.celebTest}/{folder}/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "rows=h.img_size  #Number of Pixels in the Rows for Input. \n",
    "cols=h.img_size  #Number of Pixels in Columns for Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model=MobileNetV2(input_shape=(rows,cols,3),           \n",
    "                    include_top=False,\n",
    "                    weights='imagenet')   \n",
    "\n",
    "#Un-Freeze all the pretrained layers of 'MobileNetV2 for Training.\n",
    "trained_model.trainable=True \n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer=trained_model.get_layer('out_relu')   \n",
    "last_layer_output=last_layer.output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation in train dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                rotation_range=20,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "                                 \n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(h.celebTrain,\n",
    "                                                  target_size=(rows,cols),\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory(h.celebTest,\n",
    "                                                target_size=(rows,cols),\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.GlobalAveragePooling2D()(last_layer_output)\n",
    "\n",
    "#Add a Dropout layer.\n",
    "x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "# Add a final softmax layer for classification.\n",
    "x = tf.keras.layers.Dense(h.celeb_nbr,activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(trained_model.input,x) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "#Summary of the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "result=model.fit(train_generator,\n",
    "                 validation_data=test_generator,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = result.history['accuracy']\n",
    "val_acc = result.history['val_accuracy']\n",
    "\n",
    "loss = result.history['loss']\n",
    "val_loss = result.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(9, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(h.modelsVCeleb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
