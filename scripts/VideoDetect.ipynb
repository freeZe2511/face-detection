{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python) (0.18.2)\n",
      "Installing collected packages: ffmpeg-python\n",
      "Successfully installed ffmpeg-python-0.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/src/ffmpegTest/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "import numpy as np\n",
    "path = os.getcwd()\n",
    "abspath = os.path.abspath(os.path.join(path, os.pardir))\n",
    "\n",
    "inputPath = f'{abspath}/ffmpegTest/'\n",
    "print(inputPath)\n",
    "\n",
    "in_filename = inputPath + 'vid.mp4'\n",
    "out_filename = inputPath + 'test.mp4'\n",
    "overlay_filename = inputPath + 'box.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1118400 into shape (1000,1000,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-60b5c8447951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     in_frame = (\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1118400 into shape (1000,1000,3)"
     ]
    }
   ],
   "source": [
    "process1 = (\n",
    "    ffmpeg\n",
    "    .input(in_filename)\n",
    "    .output('pipe:', format='rawvideo', pix_fmt='rgb24', vframes=8)\n",
    "    .run_async(pipe_stdout=True)\n",
    ")\n",
    "\n",
    "process2 = (\n",
    "    ffmpeg\n",
    "    .input('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height))\n",
    "    .output(out_filename, pix_fmt='yuv420p')\n",
    "    .overwrite_output()\n",
    "    .run_async(pipe_stdin=True)\n",
    ")\n",
    "\n",
    "while True:\n",
    "    in_bytes = process1.stdout.read(width * height * 3)\n",
    "    if not in_bytes:\n",
    "        break\n",
    "    in_frame = (\n",
    "        np\n",
    "        .frombuffer(in_bytes, np.uint8)\n",
    "        .reshape([height, width, 3])\n",
    "    )\n",
    "\n",
    "    # See examples/tensorflow_stream.py:\n",
    "    out_frame = in_frame\n",
    "\n",
    "    process2.stdin.write(\n",
    "        out_frame\n",
    "        .astype(np.uint8)\n",
    "        .tobytes()\n",
    "    )\n",
    "\n",
    "process2.stdin.close()\n",
    "process1.wait()\n",
    "process2.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from matplotlib import pyplot as plt\n",
    "import ffmpeg\n",
    "import ipywidgets as widgets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = ffmpeg.probe(in_filename)\n",
    "video_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')\n",
    "width = int(video_info['width'])\n",
    "height = int(video_info['height'])\n",
    "num_frames = int(video_info['nb_frames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1382d1c5e841f6b16bcca23b3a3de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='frame', max=901), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out, err = (\n",
    "    ffmpeg\n",
    "    .input(in_filename)\n",
    "    .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
    "    .run(capture_stdout=True)\n",
    ")\n",
    "video = (\n",
    "    np\n",
    "    .frombuffer(out, np.uint8)\n",
    "    .reshape([-1, height, width, 3])\n",
    ")\n",
    "\n",
    "@interact(frame=(0, num_frames))\n",
    "def show_frame(frame=0):\n",
    "    plt.imshow(video[frame,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb509a6ae1346c7b1f539dd6f331b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='enable_overlay'), Checkbox(value=True, description='en…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def extract_frame(stream, frame_num):\n",
    "    while isinstance(stream, ffmpeg.nodes.OutputStream):\n",
    "        stream = stream.node.incoming_edges[0].upstream_node.stream()\n",
    "    out, _ = (\n",
    "        stream\n",
    "        .filter_('select', 'gte(n,{})'.format(frame_num))\n",
    "        .output('pipe:', format='rawvideo', pix_fmt='rgb24', vframes=1)\n",
    "        .run(capture_stdout=True, capture_stderr=True)\n",
    "    )\n",
    "    return np.frombuffer(out, np.uint8).reshape([height, width, 3])\n",
    "\n",
    "\n",
    "def png_to_np(png_bytes):\n",
    "    buffer = BytesIO(png_bytes)\n",
    "    pil_image = Image.open(buffer)\n",
    "    return np.array(pil_image)\n",
    "    \n",
    "\n",
    "def build_graph(\n",
    "        enable_overlay, flip_overlay, enable_box, box_x, box_y,\n",
    "        thickness, color):\n",
    "\n",
    "    stream = ffmpeg.input(in_filename)\n",
    "\n",
    "    if enable_overlay:\n",
    "        overlay = ffmpeg.input(overlay_filename)\n",
    "        if flip_overlay:\n",
    "            overlay = overlay.hflip()\n",
    "        stream = stream.overlay(overlay)\n",
    "\n",
    "    if enable_box:\n",
    "        stream = stream.drawbox(\n",
    "            box_x, box_y, 120, 120, color=color, t=thickness)\n",
    "\n",
    "    return stream.output(out_filename)\n",
    "\n",
    "\n",
    "def show_image(ax, stream, frame_num):\n",
    "    try:\n",
    "        image = extract_frame(stream, frame_num)\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "    except ffmpeg.Error as e:\n",
    "        print(e.stderr.decode())\n",
    "\n",
    "\n",
    "def show_graph(ax, stream, detail):\n",
    "    data = ffmpeg.view(stream, detail=detail, pipe=True)\n",
    "    image = png_to_np(data)\n",
    "    ax.imshow(image, aspect='equal', interpolation='hanning')\n",
    "    ax.set_xlim(0, 1100)\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "@interact(\n",
    "    frame_num=(0, num_frames),\n",
    "    box_x=(0, 200),\n",
    "    box_y=(0, 200),\n",
    "    thickness=(1, 40),\n",
    "    color=['red', 'green', 'magenta', 'blue'],\n",
    ")\n",
    "def f(\n",
    "        enable_overlay=True,\n",
    "        enable_box=True,\n",
    "        flip_overlay=True,\n",
    "        graph_detail=False,\n",
    "        frame_num=0,\n",
    "        box_x=50,\n",
    "        box_y=50,\n",
    "        thickness=5,\n",
    "        color='red'):\n",
    "\n",
    "    stream = build_graph(\n",
    "        enable_overlay,\n",
    "        flip_overlay,\n",
    "        enable_box,\n",
    "        box_x,\n",
    "        box_y,\n",
    "        thickness,\n",
    "        color\n",
    "    )\n",
    "\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(15,4))\n",
    "    plt.tight_layout()\n",
    "    show_image(ax0, stream, frame_num)\n",
    "    show_graph(ax1, stream, graph_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/src/ffmpegTest/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "import numpy as np\n",
    "path = os.getcwd()\n",
    "abspath = os.path.abspath(os.path.join(path, os.pardir))\n",
    "\n",
    "inputPath = f'{abspath}/ffmpegTest/'\n",
    "print(inputPath)\n",
    "\n",
    "in_filename = inputPath + 'merkel_Trim.mp4'\n",
    "out_filename = inputPath + 'test.mp4'\n",
    "overlay_filename = inputPath + 'pic.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "ffmpeg error (see stderr output for detail)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d8cece51edce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m (\n\u001b[0;32m----> 8\u001b[0;31m     ffmpeg.overlay(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mborder_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ffmpeg/_run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(stream_spec, cmd, capture_stdout, capture_stderr, input, quiet, overwrite_output)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ffmpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: ffmpeg error (see stderr output for detail)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "\n",
    "in_file = ffmpeg.input(in_filename)\n",
    "border_box = ffmpeg.input(overlay_filename)\n",
    "\n",
    "(\n",
    "    ffmpeg.overlay(\n",
    "        border_box, in_file, x=50, y=50\n",
    "    )\n",
    "    .output(out_filename)\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
