{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-metadata 1.5.0 requires absl-py<0.13,>=0.9, but you'll have absl-py 0.15.0 which is incompatible.\n",
      "grpcio-status 1.43.0 requires grpcio>=1.43.0, but you'll have grpcio 1.41.1 which is incompatible.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tflite-model-maker\n",
    "!pip install -q pycocotools\n",
    "!pip install -q opencv-python\n",
    "!pip install -q matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = model_spec.get('efficientdet_lite0') # maybe different lite1-4\n",
    "spec.model_dir=\"/logs/fit/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_val_test(dataset_dir, label_map):\n",
    "    return tuple(map(lambda set_: object_detector.DataLoader.from_pascal_voc(images_dir=os.path.join(dataset_dir, set_), annotations_dir=os.path.join(dataset_dir, set_), label_map=label_map), (\"train\", \"val\", \"test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LewisHamilton', 'SebastianVettel', 'MaxVerstappen', 'KarlLauterbach', 'CristianoRonaldo', 'LionelMessi', 'EdSheeran', 'TomCruise', 'HeleneFischer', 'ArnoldSchwarzenegger', 'GüntherJauch', 'StefanRaab', 'HeidiKlum', 'ManuelNeuer', \"ElyasM'barek\", 'JudithRakers', 'AngelaMerkel', 'WladimirPutin', 'OlafScholz', 'JoeBiden', 'DonaldTrump', 'ChristianLindner', 'AnnalenaBaerbock', 'ElonMusk', 'JeffBezos', 'BarackObama', 'ChrisPratt', 'XiJinping', 'DwayneJohnson', 'MacKenzieScott', 'AnthonyFauci', 'GeorgeClooney', 'BradPitt', 'KobeBryant', \"ShaquilleO'Neal\", 'VinDiesel', 'JasonMomoa', 'ChrisHemsworth', 'TomHiddleston', 'BenedictCumberbatch', 'ChadwickBoseman', 'LeBronJames', 'MichaelJordan', 'MichaelJackson', 'LeonardoDiCaprio', 'TomHanks', 'WillSmith', 'DenzelWashington', 'RobertDowneyJr', 'TomHardy', 'MorganFreeman', 'NovakDjokovic', 'RogerFederer', 'ChristianBale', 'SylvesterStallone', 'AnnaFaris', 'AngelinaJolie', 'HillaryClinton', 'JustinBieber', 'RyanGosling', 'EllenDegeneres', 'LadyGaga', 'MilesCyrus', 'DieterBohlen', 'BillGates', 'WarrenBuffett', 'ArianaGrande', 'JuliaRoberts', 'ShawnMendes', 'AmanaSeyfried', 'AlvaroSoler', 'MarkForster']\n"
     ]
    }
   ],
   "source": [
    "text_file = open(\"./assets/list_promis.txt\", \"r\")\n",
    "query_array = text_file.read().split(',\\n')\n",
    "print(query_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "path = os.getcwd()\n",
    "abspath = os.path.abspath(os.path.join(path, os.pardir))\n",
    "\n",
    "datapath = abspath + \"/datasetV2/\"\n",
    "outpath =  f'{abspath}/models/TF_V3/'\n",
    "\n",
    "if not os.path.exists(outpath):\n",
    "    print(outpath)\n",
    "    os.mkdir(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'RafaelNadal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6803a6876940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabelmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_train_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-f0eea7cb3578>\u001b[0m in \u001b[0;36mread_train_val_test\u001b[0;34m(dataset_dir, label_map)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_train_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pascal_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-f0eea7cb3578>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(set_)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_train_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pascal_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/data_util/object_detector_dataloader.py\u001b[0m in \u001b[0;36mfrom_pascal_voc\u001b[0;34m(cls, images_dir, annotations_dir, label_map, annotation_filenames, ignore_difficult_instances, num_shards, max_num_images, cache_dir, cache_prefix_filename)\u001b[0m\n\u001b[1;32m    215\u001b[0m           \u001b[0mmax_num_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_num_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m           ignore_difficult_instances=ignore_difficult_instances)\n\u001b[0;32m--> 217\u001b[0;31m       cache_writer.write_files(\n\u001b[0m\u001b[1;32m    218\u001b[0m           \u001b[0mcache_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m           \u001b[0mannotations_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/data_util/object_detector_dataloader_util.py\u001b[0m in \u001b[0;36mwrite_files\u001b[0;34m(self, cache_files, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'On image %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m       tf_example = create_pascal_tfrecord.dict_to_tf_example(\n\u001b[0m\u001b[1;32m    253\u001b[0m           \u001b[0mxml_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/third_party/efficientdet/dataset/create_pascal_tfrecord.py\u001b[0m in \u001b[0;36mdict_to_tf_example\u001b[0;34m(data, images_dir, label_map_dict, unique_id, ignore_difficult_instances, ann_json_dict)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mymin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mclasses_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'truncated'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Unspecified'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mtruncated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'RafaelNadal'"
     ]
    }
   ],
   "source": [
    "labelmap = query_array\n",
    "train_data, validation_data, test_data = read_train_val_test(datapath, labelmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f77528306b5789af\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f77528306b5789af\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir /logs/fit/test/ --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "738/738 [==============================] - 367s 477ms/step - det_loss: 1.3986 - cls_loss: 1.2096 - box_loss: 0.0038 - reg_l2_loss: 0.0729 - loss: 1.4714 - learning_rate: 0.0140 - gradient_norm: 1.4132 - val_det_loss: 0.9516 - val_cls_loss: 0.8561 - val_box_loss: 0.0019 - val_reg_l2_loss: 0.0730 - val_loss: 1.0247\n",
      "Epoch 2/5\n",
      "637/738 [========================>.....] - ETA: 45s - det_loss: 0.9154 - cls_loss: 0.8240 - box_loss: 0.0018 - reg_l2_loss: 0.0730 - loss: 0.9884 - learning_rate: 0.0142 - gradient_norm: 1.3333"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fda738f012cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_whole_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/task/object_detector.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, train_data, model_spec, validation_data, epochs, batch_size, train_whole_model, do_train)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Retraining the models...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/task/object_detector.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, validation_data, epochs, batch_size)\u001b[0m\n\u001b[1;32m    121\u001b[0m       validation_ds, validation_steps, val_json_file = self._get_dataset_and_steps(\n\u001b[1;32m    122\u001b[0m           validation_data, batch_size, is_training=False)\n\u001b[0;32m--> 123\u001b[0;31m       return self.model_spec.train(self.model, train_ds, steps_per_epoch,\n\u001b[0m\u001b[1;32m    124\u001b[0m                                    \u001b[0mvalidation_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                                    batch_size, val_json_file)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/object_detector_spec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, train_dataset, steps_per_epoch, val_dataset, validation_steps, epochs, batch_size, val_json_file)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_experimental\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = object_detector.create(train_data, model_spec=spec, batch_size=16, train_whole_model=True, validation_data=validation_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 212s 4s/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.66493195,\n",
       " 'AP50': 0.77795243,\n",
       " 'AP75': 0.75517076,\n",
       " 'APs': 0.2176599,\n",
       " 'APm': 0.48967555,\n",
       " 'APl': 0.69998926,\n",
       " 'ARmax1': 0.74306005,\n",
       " 'ARmax10': 0.8323864,\n",
       " 'ARmax100': 0.83526784,\n",
       " 'ARs': 0.38333333,\n",
       " 'ARm': 0.7039489,\n",
       " 'ARl': 0.85815537,\n",
       " 'AP_/LewisHamilton': 0.54521936,\n",
       " 'AP_/SebastianVettel': 0.5841006,\n",
       " 'AP_/MaxVerstappen': 0.69106203,\n",
       " 'AP_/KarlLauterbach': 0.8064475,\n",
       " 'AP_/CristianoRonaldo': 0.7100038,\n",
       " 'AP_/LionelMessi': 0.5224295,\n",
       " 'AP_/EdSheeran': 0.7760605,\n",
       " 'AP_/TomCruise': 0.6955497,\n",
       " 'AP_/HeleneFischer': 0.6301009,\n",
       " 'AP_/ArnoldSchwarzenegger': 0.6310288,\n",
       " 'AP_/GüntherJauch': 0.700951,\n",
       " 'AP_/StefanRaab': 0.5042378,\n",
       " 'AP_/HeidiKlum': 0.69642603,\n",
       " 'AP_/ManuelNeuer': 0.7010178,\n",
       " \"AP_/ElyasM'barek\": 0.8099643,\n",
       " 'AP_/JudithRakers': 0.5114743,\n",
       " 'AP_/AngelaMerkel': 0.76910394,\n",
       " 'AP_/WladimirPutin': 0.65886945,\n",
       " 'AP_/OlafScholz': 0.76780844,\n",
       " 'AP_/JoeBiden': 0.71000177,\n",
       " 'AP_/DonaldTrump': 0.7024872,\n",
       " 'AP_/ChristianLindner': 0.6318615,\n",
       " 'AP_/AnnalenaBaerbock': 0.88129455,\n",
       " 'AP_/ElonMusk': 0.81134284,\n",
       " 'AP_/JeffBezos': 0.74052936,\n",
       " 'AP_/BarackObama': 0.75422335,\n",
       " 'AP_/ChrisPratt': 0.5802808,\n",
       " 'AP_/XiJinping': 0.8730599,\n",
       " 'AP_/DwayneJohnson': 0.59025574,\n",
       " 'AP_/MacKenzieScott': 0.55621994,\n",
       " 'AP_/AnthonyFauci': 0.7905753,\n",
       " 'AP_/GeorgeClooney': 0.70214367,\n",
       " 'AP_/BradPitt': 0.6562013,\n",
       " 'AP_/KobeBryant': 0.5463816,\n",
       " \"AP_/ShaquilleO'Neal\": 0.3561264,\n",
       " 'AP_/VinDiesel': 0.6480463,\n",
       " 'AP_/JasonMomoa': 0.6622335,\n",
       " 'AP_/ChrisHemsworth': 0.7051662,\n",
       " 'AP_/TomHiddleston': 0.62494195,\n",
       " 'AP_/BenedictCumberbatch': 0.748095,\n",
       " 'AP_/ChadwickBoseman': 0.79549354,\n",
       " 'AP_/LeBronJames': 0.6038945,\n",
       " 'AP_/MichaelJordan': 0.3066653,\n",
       " 'AP_/MichaelJackson': 0.6104169,\n",
       " 'AP_/LeonardoDiCaprio': 0.68115157,\n",
       " 'AP_/TomHanks': 0.6980578,\n",
       " 'AP_/WillSmith': 0.78294086,\n",
       " 'AP_/DenzelWashington': 0.81529,\n",
       " 'AP_/RobertDowneyJr': 0.57056946,\n",
       " 'AP_/TomHardy': 0.68398577,\n",
       " 'AP_/MorganFreeman': 0.73173064,\n",
       " 'AP_/NovakDjokovic': 0.60813206,\n",
       " 'AP_/RafaelNadal': 0.45878944,\n",
       " 'AP_/RogerFederer': 0.6610491,\n",
       " 'AP_/ChristianBale': 0.6120318,\n",
       " 'AP_/SylvesterStallone': 0.6326664}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(export_dir=outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_tflite(outpath + 'model.tflite', validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"x\": self.x,\n",
    "            \"y\": self.y,\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.to_json())\n",
    "\n",
    "class BoundingBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.center = Point((xmin + xmax) // 2, (ymin + ymax) // 2)\n",
    "        self.width = xmax - xmin\n",
    "        self.height = ymax - ymin\n",
    "        self.area = self.width * self.height\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"xmin\": self.xmin,\n",
    "            \"ymin\": self.ymin,\n",
    "            \"xmax\": self.xmax,\n",
    "            \"ymax\": self.ymax,\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.to_json())\n",
    "\n",
    "class Detection:\n",
    "    def __init__(self, class_, confidence, xmin, ymin, xmax, ymax):\n",
    "        self.class_ = class_\n",
    "        self.confidence = confidence\n",
    "        self.bounding_box = BoundingBox(xmin=xmin, ymin=ymin, xmax=xmax, ymax=ymax)\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"class\": self.class_,\n",
    "            \"confidence\": self.confidence,\n",
    "            \"box\": self.bounding_box.to_json(),\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.to_json())\n",
    "\n",
    "\n",
    "class EfficientDetLite:\n",
    "    def __init__(self, model_path, labelmap):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "\n",
    "        # iti = input tensor index\n",
    "        input_details = self.interpreter.get_input_details()\n",
    "        self.iti_image = input_details[0][\"index\"]\n",
    "        self.it_image_dtype = input_details[0][\"dtype\"]\n",
    "        self.it_image_width = input_details[0][\"shape\"][2]\n",
    "        self.it_image_height = input_details[0][\"shape\"][1]\n",
    "\n",
    "        # oti = output tensor index\n",
    "        output_details = self.interpreter.get_output_details()\n",
    "        self.oti_bounding_boxes = output_details[1][\"index\"]\n",
    "        self.oti_classes = output_details[3][\"index\"]\n",
    "        self.oti_confidences = output_details[0][\"index\"]\n",
    "\n",
    "        self.labelmap = labelmap\n",
    "\n",
    "    def detect(self, image, threshold=0):\n",
    "        input_tensor = self.prepare_image(image)\n",
    "        self.interpreter.set_tensor(self.iti_image, input_tensor)\n",
    "        self.interpreter.invoke()\n",
    "\n",
    "        bounding_boxes = self.interpreter.get_tensor(self.oti_bounding_boxes)[0]\n",
    "        classes = self.interpreter.get_tensor(self.oti_classes)[0]\n",
    "        confidences = self.interpreter.get_tensor(self.oti_confidences)[0]\n",
    "        detections = zip(classes, bounding_boxes, confidences)\n",
    "        detections = filter(lambda x: x[2] >= threshold, detections)\n",
    "\n",
    "        def tensors2detection(x):\n",
    "            def clamp(n, min_, max_):\n",
    "                return max(min(max_, n), min_)\n",
    "\n",
    "            xmin = clamp(int(round(x[1][1] * image.shape[1])), 0, image.shape[1])\n",
    "            ymin = clamp(int(round(x[1][0] * image.shape[0])), 0, image.shape[0])\n",
    "            xmax = clamp(int(round(x[1][3] * image.shape[1])), 0, image.shape[1])\n",
    "            ymax = clamp(int(round(x[1][2] * image.shape[0])), 0, image.shape[0])\n",
    "            name = str(self.labelmap[int(x[0])])\n",
    "            confidence = float(x[2])\n",
    "\n",
    "            detection = Detection(name, confidence, xmin, ymin, xmax, ymax)\n",
    "            return detection\n",
    "\n",
    "        detections = map(lambda x: tensors2detection(x), detections)\n",
    "        detections = list(detections)\n",
    "        return detections\n",
    "\n",
    "    def prepare_image(self, image):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (self.it_image_width, self.it_image_height), interpolation=cv2.INTER_NEAREST)\n",
    "        tensor = np.reshape(image, (1, self.it_image_height, self.it_image_width, 3))\n",
    "        tensor = tensor.astype(self.it_image_dtype)\n",
    "        return tensor\n",
    "\n",
    "def show_image(image, label=None, scale=1):\n",
    "    show_images([image], labels=[label] if label is not None else None, scale=scale)\n",
    "\n",
    "\n",
    "def show_images(images, labels=None, scale=1):\n",
    "    figsize = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.figure(figsize=(figsize[0] * scale, figsize[1] * scale))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        image = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "        if labels is not None:\n",
    "            plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_detection(image, detection, scale=1, thickness=1, colors=None, confidence=True):\n",
    "    show_image(draw_detections(image,\n",
    "                               [detection],\n",
    "                               scale=scale,\n",
    "                               thickness=thickness,\n",
    "                               colors=colors,\n",
    "                               confidence=confidence))\n",
    "\n",
    "\n",
    "def show_detections(image, detections, scale=1, thickness=1, colors=None, confidence=True):\n",
    "    show_image(draw_detections(image,\n",
    "                               detections,\n",
    "                               scale=scale,\n",
    "                               thickness=thickness,\n",
    "                               colors=colors,\n",
    "                               confidence=confidence))\n",
    "\n",
    "\n",
    "def draw_detection(image, detection, scale=1, thickness=1, colors=None, confidence=True):\n",
    "    return draw_detections(image, [detection], scale, thickness, colors, confidence)\n",
    "\n",
    "\n",
    "def draw_detections(image, detections, scale=1, thickness=1, colors=None, confidence=True):\n",
    "    colors = {} if colors is None else {k: tuple(reversed(v)) for k, v in colors.items()}\n",
    "    result = image.copy()\n",
    "    for detection in detections:\n",
    "        print(detection)\n",
    "        xmin = int(detection.bounding_box.xmin)\n",
    "        ymin = int(detection.bounding_box.ymin)\n",
    "        xmax = int(detection.bounding_box.xmax)\n",
    "        ymax = int(detection.bounding_box.ymax)\n",
    "        color = colors.get(detection.class_)\n",
    "        if color is None:\n",
    "            color = (0, 0, 0)\n",
    "        result = cv2.rectangle(result, (xmin, ymin), (xmax, ymax), color, thickness)\n",
    "        if confidence:\n",
    "            text = \"{:.2f}\".format(float(detection.confidence))\n",
    "            #text = f\"{detection.class}\"\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            textsize = cv2.getTextSize(text, font, scale, thickness)[0]\n",
    "            result = cv2.putText(result,\n",
    "                                 text,\n",
    "                                 (\n",
    "                                     ((xmin + xmax) - textsize[0]) // 2,\n",
    "                                     ((ymin + ymax) + textsize[1]) // 2\n",
    "                                 ),\n",
    "                                 font,\n",
    "                                 scale,\n",
    "                                 color,\n",
    "                                 thickness,\n",
    "                                 cv2.LINE_AA)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientDetLite(outpath + 'model.tflite', labelmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datapath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dfa0eebcd075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'test/001_4d0d9a57.jpg'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# change to exisiting image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datapath' is not defined"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(datapath + 'test/001_4d0d9a57.jpg') # change to exisiting image\n",
    "\n",
    "print(image)\n",
    "\n",
    "detections = model.detect(image, threshold=0.6)\n",
    "\n",
    "for detection in detections:\n",
    "  print(detection)\n",
    "\n",
    "show_detections(image, detections, thickness=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
